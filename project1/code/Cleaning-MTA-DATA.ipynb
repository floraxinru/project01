{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes data frames of corresponding week data.\n",
    "# The data ends with the last day of the file name.\n",
    "\n",
    "df1 = pd.read_csv('/Users/luken2/Documents/GitHub/project01/project1/data/june82019.txt')\n",
    "df2 = pd.read_csv('/Users/luken2/Documents/GitHub/project01/project1/data/june12019.txt')\n",
    "df3 = pd.read_csv('/Users/luken2/Documents/GitHub/project01/project1/data/may252019.txt')\n",
    "df4 = pd.read_csv('/Users/luken2/Documents/GitHub/project01/project1/data/may182019.txt')\n",
    "df5 = pd.read_csv('/Users/luken2/Documents/GitHub/project01/project1/data/may112019.txt')\n",
    "df6 = pd.read_csv('/Users/luken2/Documents/GitHub/project01/project1/data/may42019.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Datetime column from date and time columns\n",
    "\n",
    "df1['DATETIME'] = df1['DATE'] + ' ' + df1['TIME']\n",
    "df2['DATETIME'] = df2['DATE'] + ' ' + df2['TIME']\n",
    "df3['DATETIME'] = df3['DATE'] + ' ' + df3['TIME']\n",
    "df4['DATETIME'] = df4['DATE'] + ' ' + df4['TIME']\n",
    "df5['DATETIME'] = df5['DATE'] + ' ' + df5['TIME']\n",
    "df6['DATETIME'] = df6['DATE'] + ' ' + df6['TIME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting dataframe's 'DATETIME' columns datatypes from objects to datetime one  \n",
    "### at a time because jupyter notebook took too long to run them all in one cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['DATETIME'] = pd.to_datetime(df1['DATETIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['DATETIME'] = pd.to_datetime(df2['DATETIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['DATETIME'] = pd.to_datetime(df3['DATETIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['DATETIME'] = pd.to_datetime(df4['DATETIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['DATETIME'] = pd.to_datetime(df5['DATETIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['DATETIME'] = pd.to_datetime(df6['DATETIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of unnecessary columns\n",
    "\n",
    "df1 = df1[['C/A', 'UNIT', 'SCP', 'STATION','DATE', 'ENTRIES', 'DATETIME']]\n",
    "df2 = df2[['C/A', 'UNIT', 'SCP', 'STATION','DATE', 'ENTRIES', 'DATETIME']]\n",
    "df3 = df3[['C/A', 'UNIT', 'SCP', 'STATION','DATE', 'ENTRIES', 'DATETIME']]\n",
    "df4 = df4[['C/A', 'UNIT', 'SCP', 'STATION','DATE', 'ENTRIES', 'DATETIME']]\n",
    "df5 = df5[['C/A', 'UNIT', 'SCP', 'STATION','DATE', 'ENTRIES', 'DATETIME']]\n",
    "df6 = df6[['C/A', 'UNIT', 'SCP', 'STATION','DATE', 'ENTRIES', 'DATETIME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new column for day of the week using pandas datetime function\n",
    "\n",
    "df1['DAY_OF_WEEK'] = df1['DATETIME'].dt.day_name()\n",
    "df2['DAY_OF_WEEK'] = df2['DATETIME'].dt.day_name()\n",
    "df3['DAY_OF_WEEK'] = df3['DATETIME'].dt.day_name()\n",
    "df4['DAY_OF_WEEK'] = df4['DATETIME'].dt.day_name()\n",
    "df5['DAY_OF_WEEK'] = df5['DATETIME'].dt.day_name()\n",
    "df6['DAY_OF_WEEK'] = df6['DATETIME'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data.  Getting rid of outliers, capping top because MOSHOLU PWY station: 451208340 Net\n",
    "# AVENUE H: 1391496 Net\n",
    "\n",
    "df1 = df1.loc[df1['ENTRIES'].apply(lambda x: x > 10000 and x < 1000000)]\n",
    "df2 = df2.loc[df2['ENTRIES'].apply(lambda x: x > 10000 and x < 1000000)]\n",
    "df3 = df3.loc[df3['ENTRIES'].apply(lambda x: x > 10000 and x < 1000000)]\n",
    "df4 = df4.loc[df4['ENTRIES'].apply(lambda x: x > 10000 and x < 1000000)]\n",
    "df5 = df5.loc[df5['ENTRIES'].apply(lambda x: x > 10000 and x < 1000000)]\n",
    "df6 = df6.loc[df6['ENTRIES'].apply(lambda x: x > 10000 and x < 1000000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C/A</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>SCP</th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>ENTRIES</th>\n",
       "      <th>DATETIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-06-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>05/18/2019</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>196351</td>\n",
       "      <td>2019-05-18 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-06-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>05/19/2019</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>196909</td>\n",
       "      <td>2019-05-19 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-06-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>05/20/2019</td>\n",
       "      <td>Monday</td>\n",
       "      <td>198320</td>\n",
       "      <td>2019-05-20 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-06-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>05/21/2019</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>199779</td>\n",
       "      <td>2019-05-21 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-06-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>05/22/2019</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>201317</td>\n",
       "      <td>2019-05-22 20:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C/A  UNIT       SCP STATION        DATE DAY_OF_WEEK  ENTRIES  \\\n",
       "0  A002  R051  02-06-00   59 ST  05/18/2019    Saturday   196351   \n",
       "1  A002  R051  02-06-00   59 ST  05/19/2019      Sunday   196909   \n",
       "2  A002  R051  02-06-00   59 ST  05/20/2019      Monday   198320   \n",
       "3  A002  R051  02-06-00   59 ST  05/21/2019     Tuesday   199779   \n",
       "4  A002  R051  02-06-00   59 ST  05/22/2019   Wednesday   201317   \n",
       "\n",
       "             DATETIME  \n",
       "0 2019-05-18 20:00:00  \n",
       "1 2019-05-19 20:00:00  \n",
       "2 2019-05-20 20:00:00  \n",
       "3 2019-05-21 20:00:00  \n",
       "4 2019-05-22 20:00:00  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting values of entries on each day for each turnstile, Unit, C/A, and Station\n",
    "# By getting max value of entries each day\n",
    "\n",
    "df1_sorted = df1.groupby(['C/A', 'UNIT', 'SCP', 'STATION', 'DATE', 'DAY_OF_WEEK'], as_index=False).max()\n",
    "df2_sorted = df2.groupby(['C/A', 'UNIT', 'SCP', 'STATION', 'DATE', 'DAY_OF_WEEK'], as_index=False).max()\n",
    "df3_sorted = df3.groupby(['C/A', 'UNIT', 'SCP', 'STATION', 'DATE', 'DAY_OF_WEEK'], as_index=False).max()\n",
    "df4_sorted = df4.groupby(['C/A', 'UNIT', 'SCP', 'STATION', 'DATE', 'DAY_OF_WEEK'], as_index=False).max()\n",
    "df5_sorted = df5.groupby(['C/A', 'UNIT', 'SCP', 'STATION', 'DATE', 'DAY_OF_WEEK'], as_index=False).max()\n",
    "df6_sorted = df6.groupby(['C/A', 'UNIT', 'SCP', 'STATION', 'DATE', 'DAY_OF_WEEK'], as_index=False).max()\n",
    "df3_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>ENTRIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1137051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1114661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1106629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1110159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1131314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STATION DAY_OF_WEEK  ENTRIES\n",
       "0    1 AV      Friday  1137051\n",
       "1    1 AV      Monday  1114661\n",
       "2    1 AV    Saturday  1106629\n",
       "3    1 AV      Sunday  1110159\n",
       "4    1 AV    Thursday  1131314"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summing entries for each turnstiles at every station.  Sorting by day and station.\n",
    "\n",
    "df1_stations = df1_sorted.groupby(['STATION', 'DAY_OF_WEEK'], as_index=False).sum()\n",
    "df2_stations = df2_sorted.groupby(['STATION', 'DAY_OF_WEEK'], as_index=False).sum()\n",
    "df3_stations = df3_sorted.groupby(['STATION', 'DAY_OF_WEEK'], as_index=False).sum()\n",
    "df4_stations = df4_sorted.groupby(['STATION', 'DAY_OF_WEEK'], as_index=False).sum()\n",
    "df5_stations = df5_sorted.groupby(['STATION', 'DAY_OF_WEEK'], as_index=False).sum()\n",
    "df6_stations = df6_sorted.groupby(['STATION', 'DAY_OF_WEEK'], as_index=False).sum()\n",
    "df3_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>ENTRIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1137051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1106629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>103 ST</td>\n",
       "      <td>Friday</td>\n",
       "      <td>615307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>103 ST</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>606365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>104 ST</td>\n",
       "      <td>Friday</td>\n",
       "      <td>933866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATION DAY_OF_WEEK  ENTRIES\n",
       "0     1 AV      Friday  1137051\n",
       "2     1 AV    Saturday  1106629\n",
       "7   103 ST      Friday   615307\n",
       "9   103 ST    Saturday   606365\n",
       "14  104 ST      Friday   933866"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting rid of unnecessary weekday rows to calculate net entries each week\n",
    "\n",
    "df1_sat_fri = df1_stations.loc[(df1_stations['DAY_OF_WEEK'] == 'Friday') | (df1_stations['DAY_OF_WEEK'] == 'Saturday')]\n",
    "df2_sat_fri = df2_stations.loc[(df2_stations['DAY_OF_WEEK'] == 'Friday') | (df2_stations['DAY_OF_WEEK'] == 'Saturday')]\n",
    "df3_sat_fri = df3_stations.loc[(df3_stations['DAY_OF_WEEK'] == 'Friday') | (df3_stations['DAY_OF_WEEK'] == 'Saturday')]\n",
    "df4_sat_fri = df4_stations.loc[(df4_stations['DAY_OF_WEEK'] == 'Friday') | (df4_stations['DAY_OF_WEEK'] == 'Saturday')]\n",
    "df5_sat_fri = df5_stations.loc[(df5_stations['DAY_OF_WEEK'] == 'Friday') | (df5_stations['DAY_OF_WEEK'] == 'Saturday')]\n",
    "df6_sat_fri = df6_stations.loc[(df6_stations['DAY_OF_WEEK'] == 'Friday') | (df6_stations['DAY_OF_WEEK'] == 'Saturday')]\n",
    "df3_sat_fri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding stations with missing data \n",
    "# df1_sat_fri['STATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing data for certain stations that have missing data for week of June 2-8th\n",
    "\n",
    "df1_sat_fri = df1_sat_fri[df1_sat_fri.STATION != 'CANARSIE-ROCKAW']\n",
    "df1_sat_fri = df1_sat_fri[df1_sat_fri.STATION != 'FRANKLIN AV']\n",
    "df1_sat_fri = df1_sat_fri[df1_sat_fri.STATION != 'NEWARK HM HE']\n",
    "df1_sat_fri = df1_sat_fri[df1_sat_fri.STATION != 'NEWARK C']\n",
    "df1_sat_fri = df1_sat_fri[df1_sat_fri.STATION != 'PATH WTC 2']\n",
    "df1_sat_fri = df1_sat_fri[df1_sat_fri.STATION != 'RIT-ROOSEVELT']\n",
    "df1_sat_fri = df1_sat_fri[df1_sat_fri.STATION != '5 AVE']\n",
    "df1_sat_fri = df1_sat_fri[df1_sat_fri.STATION != 'NEWARK HW BMEBE']\n",
    "df1_sat_fri = df1_sat_fri[df1_sat_fri.STATION != 'HARRISON']\n",
    "df1_sat_fri = df1_sat_fri[df1_sat_fri.STATION != 'NEWARK BM BW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing data for certain stations that have missing data for week of May 19-24th\n",
    "\n",
    "df3_sat_fri = df3_sat_fri[df3_sat_fri.STATION != 'FRANKLIN AV']\n",
    "df3_sat_fri = df3_sat_fri[df3_sat_fri.STATION != 'ORCHARD BEACH']\n",
    "df3_sat_fri = df3_sat_fri[df3_sat_fri.STATION != 'FOREST AVE']\n",
    "df3_sat_fri = df3_sat_fri[df3_sat_fri.STATION != 'CANARSIE-ROCKAW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_sat_fri = df4_sat_fri[df4_sat_fri.STATION != 'FRANKLIN AV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing data for certain stations that have missing data for week of May 5th-11th\n",
    "\n",
    "df5_sat_fri = df5_sat_fri[df5_sat_fri.STATION != 'E 149 ST']\n",
    "df5_sat_fri = df5_sat_fri[df5_sat_fri.STATION != '42 ST-BRYANT PK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing data for certain stations that have missing data for week ending on May 4th\n",
    "\n",
    "df6_sat_fri = df6_sat_fri[df6_sat_fri.STATION != 'EASTN PKWY-MUSM']\n",
    "df6_sat_fri = df6_sat_fri[df6_sat_fri.STATION != '61 ST WOODSIDE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting data frames between stations Friday values and Saturday values\n",
    "\n",
    "df1_fri = df1_sat_fri.loc[(df1_sat_fri['DAY_OF_WEEK'] == 'Friday')]\n",
    "df1_fri.reset_index(drop=True, inplace=True)\n",
    "df1_sat = df1_sat_fri.loc[(df1_sat_fri['DAY_OF_WEEK'] == 'Saturday')]\n",
    "df1_sat.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_fri = df2_sat_fri.loc[(df2_sat_fri['DAY_OF_WEEK'] == 'Friday')]\n",
    "df2_fri.reset_index(drop=True, inplace=True)\n",
    "df2_sat = df2_sat_fri.loc[(df2_sat_fri['DAY_OF_WEEK'] == 'Saturday')]\n",
    "df2_sat.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_fri = df3_sat_fri.loc[(df3_sat_fri['DAY_OF_WEEK'] == 'Friday')]\n",
    "df3_fri.reset_index(drop=True, inplace=True)\n",
    "df3_sat = df3_sat_fri.loc[(df3_sat_fri['DAY_OF_WEEK'] == 'Saturday')]\n",
    "df3_sat.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_fri = df4_sat_fri.loc[(df4_sat_fri['DAY_OF_WEEK'] == 'Friday')]\n",
    "df4_fri.reset_index(drop=True, inplace=True)\n",
    "df4_sat = df4_sat_fri.loc[(df4_sat_fri['DAY_OF_WEEK'] == 'Saturday')]\n",
    "df4_sat.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5_fri = df5_sat_fri.loc[(df5_sat_fri['DAY_OF_WEEK'] == 'Friday')]\n",
    "df5_fri.reset_index(drop=True, inplace=True)\n",
    "df5_sat = df5_sat_fri.loc[(df5_sat_fri['DAY_OF_WEEK'] == 'Saturday')]\n",
    "df5_sat.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6_fri = df6_sat_fri.loc[(df6_sat_fri['DAY_OF_WEEK'] == 'Friday')]\n",
    "df6_fri.reset_index(drop=True, inplace=True)\n",
    "df6_sat = df6_sat_fri.loc[(df6_sat_fri['DAY_OF_WEEK'] == 'Saturday')]\n",
    "df6_sat.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# Making column 'NET' of each week for total entries non-cumulative by subtracting the weeks\n",
    "# starting entries each week and substracting from the ending entries\n",
    "\n",
    "df1_fri['NET'] = df1_fri['ENTRIES'] - df1_sat['ENTRIES']\n",
    "df2_fri['NET'] = df2_fri['ENTRIES'] - df2_sat['ENTRIES']\n",
    "df3_fri['NET'] = df3_fri['ENTRIES'] - df3_sat['ENTRIES']\n",
    "df4_fri['NET'] = df4_fri['ENTRIES'] - df4_sat['ENTRIES']\n",
    "df5_fri['NET'] = df5_fri['ENTRIES'] - df5_sat['ENTRIES']\n",
    "df6_fri['NET'] = df6_fri['ENTRIES'] - df6_sat['ENTRIES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sorted data frame for each week of data and sorting by highest net entries.\n",
    "\n",
    "df1_sorted = df1_fri.sort_values(by=['NET'], ascending = False)\n",
    "df2_sorted = df2_fri.sort_values(by=['NET'], ascending = False)\n",
    "df3_sorted = df3_fri.sort_values(by=['NET'], ascending = False)\n",
    "df4_sorted = df4_fri.sort_values(by=['NET'], ascending = False)\n",
    "df5_sorted = df5_fri.sort_values(by=['NET'], ascending = False)\n",
    "df6_sorted = df6_fri.sort_values(by=['NET'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making final data frame with just each station and net entries per week\n",
    "\n",
    "df1_final = df1_sorted.drop(columns=['DAY_OF_WEEK','ENTRIES'])\n",
    "df2_final = df2_sorted.drop(columns=['DAY_OF_WEEK','ENTRIES'])\n",
    "df3_final = df3_sorted.drop(columns=['DAY_OF_WEEK','ENTRIES'])\n",
    "df4_final = df4_sorted.drop(columns=['DAY_OF_WEEK','ENTRIES'])\n",
    "df5_final = df5_sorted.drop(columns=['DAY_OF_WEEK','ENTRIES'])\n",
    "df6_final = df6_sorted.drop(columns=['DAY_OF_WEEK','ENTRIES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 25 stations for each week\n",
    "\n",
    "df1_top25 = df1_final.head(25)\n",
    "df2_top25 = df2_final.head(25)\n",
    "df3_top25 = df3_final.head(25)\n",
    "df4_top25 = df4_final.head(25)\n",
    "df5_top25 = df5_final.head(25)\n",
    "df6_top25 = df6_final.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame of all top 25 stations over 6 weeks\n",
    "\n",
    "DF = pd.concat([df1_top25, df2_top25, df3_top25, df4_top25, df5_top25, df6_top25], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of top stations\n",
    "\n",
    "DF_stations_mean = DF.groupby(['STATION'], as_index=False).mean()\n",
    "DF_Final = DF_stations_mean.sort_values(by=['NET'], ascending = False)\n",
    "DF_Final_25 = DF_Final.head(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing data frame to csv\n",
    "\n",
    "DF_Final_25.to_csv('/Users/luken2/Documents/GitHub/project01/project1/data/top_25.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
